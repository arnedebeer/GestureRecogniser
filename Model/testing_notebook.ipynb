{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from model_constructor import ModelConstructor\n",
    "\n",
    "import data_loading\n",
    "import data_processing\n",
    "import model_training\n",
    "import data_visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = data_loading.load_gestures_grouped_per_candidate(use_left_hand=True, use_right_hand=True)\n",
    "all_candidates = list(all_data.keys())\n",
    "data, labels = data_loading.get_data_and_labels_from_candidates(all_candidates, all_data, input_shape=(100, 3, 1))\n",
    "i = 150\n",
    "data_visualisation.plot_data_as_graph(data[i], title=f\"{labels[i]}\")\n",
    "data_visualisation.plot_data_as_image(data[i], label=f\"{labels[i]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing reshaping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = [[540, 496, 543],\n",
    "[531, 482, 541],\n",
    "[523, 473, 538],\n",
    "[512, 459, 536],\n",
    "[502, 440, 533],\n",
    "[486, 366, 528],\n",
    "[468, 308, 524],\n",
    "[448, 271, 522],\n",
    "[426, 239, 513],\n",
    "[401, 216, 507],\n",
    "[403, 217, 506],\n",
    "[358, 203, 498],\n",
    "[282, 194, 484],\n",
    "[238, 188, 468],\n",
    "[217, 186, 442],\n",
    "[205, 182, 408],\n",
    "[198, 180, 317],\n",
    "[192, 178, 252],\n",
    "[188, 176, 224],\n",
    "[186, 176, 205],\n",
    "[185, 171, 199],\n",
    "[180, 173, 191],\n",
    "[180, 172, 185],\n",
    "[179, 171, 183],\n",
    "[176, 167, 182],\n",
    "[176, 170, 178],\n",
    "[176, 167, 177],\n",
    "[174, 169, 176],\n",
    "[174, 165, 175],\n",
    "[174, 166, 173],\n",
    "[173, 166, 173],\n",
    "[173, 163, 171],\n",
    "[170, 166, 170],\n",
    "[170, 166, 169],\n",
    "[169, 166, 168],\n",
    "[170, 162, 167],\n",
    "[168, 164, 166],\n",
    "[169, 161, 167],\n",
    "[167, 163, 164],\n",
    "[167, 163, 163],\n",
    "[166, 162, 163],\n",
    "[167, 159, 179],\n",
    "[168, 162, 217],\n",
    "[166, 161, 302],\n",
    "[165, 160, 373],\n",
    "[165, 160, 420],\n",
    "[178, 160, 451],\n",
    "[278, 174, 477],\n",
    "[362, 218, 496],\n",
    "[417, 293, 507],\n",
    "[457, 392, 515],\n",
    "[486, 441, 522],\n",
    "[508, 472, 528],\n",
    "[525, 495, 533],\n",
    "[538, 508, 537],\n",
    "[549, 523, 540],\n",
    "[557, 535, 544],\n",
    "[564, 546, 546],\n",
    "[569, 550, 547],\n",
    "[575, 559, 550],\n",
    "[577, 563, 550],\n",
    "[580, 568, 551],\n",
    "[582, 569, 556],\n",
    "[586, 574, 556],\n",
    "[588, 575, 555],\n",
    "[589, 577, 556],\n",
    "[590, 581, 556],\n",
    "[591, 583, 558],\n",
    "[593, 583, 559],\n",
    "[592, 587, 558],\n",
    "[593, 586, 560],\n",
    "[593, 587, 560],\n",
    "[593, 588, 560],\n",
    "[594, 588, 560],\n",
    "[596, 590, 559],\n",
    "[595, 590, 560],\n",
    "[595, 587, 561],\n",
    "[597, 591, 560],\n",
    "[596, 590, 560],\n",
    "[597, 593, 561],\n",
    "[596, 591, 561],\n",
    "[597, 592, 562],\n",
    "[596, 590, 562],\n",
    "[597, 589, 562],\n",
    "[597, 592, 562],\n",
    "[597, 591, 561],\n",
    "[596, 591, 561],\n",
    "[596, 589, 563],\n",
    "[596, 592, 562],\n",
    "[598, 593, 563],\n",
    "[597, 592, 560],\n",
    "[598, 590, 561],\n",
    "[596, 591, 560],\n",
    "[598, 593, 562],\n",
    "[596, 589, 563],\n",
    "[598, 593, 563],\n",
    "[595, 590, 562],\n",
    "[597, 590, 561],\n",
    "[597, 589, 562],\n",
    "[597, 592, 562]\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sample_data)\n",
    "print(len(sample_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=\"converted_model.tflite\")\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(input_details)\n",
    "print(output_details)\n",
    "\n",
    "signature = interpreter.get_signature_runner()\n",
    "array = np.array(data_processing.preprocess_data(sample_data))\n",
    "array = np.reshape(array, (20, 5, 3))\n",
    "# with np.printoptions(threshold=np.inf, precision=2, suppress=True):\n",
    "#     print(f\"array (shape={array.shape}) with reshaping through np: \")\n",
    "#     print(array)\n",
    "\n",
    "#     print(f\"reshaped (shape={reshaped.shape}) with manual reshaping: \")\n",
    "#     print(reshaped)\n",
    "\n",
    "# np.testing.assert_array_almost_equal(np.ndarray.flatten(array), np.ndarray.flatten(reshaped))\n",
    "\n",
    "# This is the output we want\n",
    "with np.printoptions(threshold=np.inf, precision=2, suppress=True):\n",
    "    print(\"array:\\n\", np.ravel(array))\n",
    "    # print(\"array:\\n\", array)\n",
    "\n",
    "\n",
    "array = np.expand_dims(array, axis=0)\n",
    "output = signature(sensor_image=array.astype(np.float32))\n",
    "print(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C++ (manual) workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_processing = data_processing.preprocess_data(sample_data) # simulate data processing\n",
    "# after_processing = sample_data\n",
    "after_processing = np.array(after_processing).astype(np.float32)\n",
    "\n",
    "# On the device we store the data transposed\n",
    "transposed = after_processing.transpose()\n",
    "# transposed = after_processing\n",
    "\n",
    "# Print transposed data\n",
    "with np.printoptions(threshold=np.inf, precision=2, suppress=True):\n",
    "    print(\"Transposed data:\", transposed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After transposing we 'cast' the data to the shape of the input tensor\n",
    "# In C++ this is done by casting the data to a float pointer with the three dimensions\n",
    "DIM1 = 20\n",
    "DIM2 = 5\n",
    "DIM3 = 3\n",
    "\n",
    "cast_array = np.reshape(transposed, (DIM3, DIM2, DIM1))\n",
    "\n",
    "reshaped = [0] * DIM1 * DIM2 * DIM3\n",
    "index = 0\n",
    "for j in range(DIM2):\n",
    "    for i in range(DIM1):\n",
    "        for k in range(DIM3):\n",
    "            reshaped[index] = cast_array[k, j, i]\n",
    "            index += 1\n",
    "\n",
    "reshaped = np.array(reshaped)\n",
    "print(reshaped.shape)\n",
    "with np.printoptions(threshold=np.inf, precision=2, suppress=True):\n",
    "    print(\"Reshaped data:\\n\", reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether they are equal\n",
    "\n",
    "np.testing.assert_array_almost_equal(np.ndarray.flatten(array), np.ndarray.flatten(reshaped))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
