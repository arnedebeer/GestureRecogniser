{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sklearn as sk\n",
    "from sklearn import model_selection\n",
    "import numpy as np\n",
    "\n",
    "import data_loading\n",
    "import data_visualisation\n",
    "from model_constructor import ModelConstructor, ModelName"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensure same seed on every run in order to get consistent results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below is necessary for starting Numpy generated random numbers\n",
    "# in a well-defined initial state.\n",
    "np.random.seed(1337)\n",
    "\n",
    "# The below is necessary for starting core Python generated random numbers\n",
    "# in a well-defined state.\n",
    "# python_random.seed(123)\n",
    "\n",
    "# The below set_seed() will make random number generation\n",
    "# in the TensorFlow backend have a well-defined initial state.\n",
    "# For further details, see:\n",
    "# https://www.tensorflow.org/api_docs/python/tf/random/set_seed\n",
    "tf.random.set_seed(5)\n",
    "\n",
    "# We also specify a random seed for sklearn, used for KFold cross validation\n",
    "sklearn_random_seed = 5354"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some compatibility checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"TF version: {tf.__version__}\")\n",
    "print(f\"Logical devices: {tf.config.list_logical_devices()}\")\n",
    "print(f\"TF built with CUDA: {tf.test.is_built_with_cuda()}\")\n",
    "print(f\"Visible devices: {tf.config.get_visible_devices()}\")\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all data that was collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gets all data and puts them into a single dictionary with the following structure:\n",
    "# {\n",
    "#     \"candidate_id\": {\n",
    "#         \"gesture_name\": [\n",
    "#             [sample1],\n",
    "#             [sample2],\n",
    "#             ...\n",
    "#         ],\n",
    "#         ...\n",
    "#     },\n",
    "#     ...\n",
    "# }\n",
    "all_data_per_candidate = data_loading.load_gestures_grouped_per_candidate(use_left_hand=True, use_right_hand=True, split_candidate_per_hand=True)\n",
    "\n",
    "all_candidates = list(all_data_per_candidate.keys())\n",
    "\n",
    "# Possibly remove unwanted candidates\n",
    "# all_candidates.remove(\"E1\")\n",
    "# all_candidates.remove(\"E6\")\n",
    "\n",
    "print(\"All candidates:\", all_candidates)\n",
    "# np.random.shuffle(all_candidates)\n",
    "# print(\"Shuffled candidates:\", all_candidates)\n",
    "\n",
    "# training_candidates = all_candidates[:int(len(all_candidates) * training_ratio)]\n",
    "# testing_candidates = all_candidates[int(len(all_candidates) * training_ratio):]\n",
    "\n",
    "# split_per_candidate = True\n",
    "\n",
    "# if not split_per_candidate:\n",
    "#     features, labels = data_loading.get_data_and_labels_from_candidates(all_data_per_candidate)\n",
    "#     training_data, testing_data, training_labels, testing_labels = sk.model_selection.train_test_split(features, labels, test_size=0.25, random_state=69)\n",
    "# else:\n",
    "#     training_data, training_labels = data_loading.get_data_and_labels_from_candidates(training_candidates, all_data_per_candidate)\n",
    "#     testing_data, testing_labels = data_loading.get_data_and_labels_from_candidates(testing_candidates, all_data_per_candidate)\n",
    "\n",
    "# print(\"Training candidates:\", training_candidates)\n",
    "# print(\"Testing candidates:\", testing_candidates)\n",
    "\n",
    "# Plot one sample to check pre-processing\n",
    "# try:\n",
    "#     data_visualisation.plot_data_as_image(training_data[0], label=training_labels[0])\n",
    "#     data_visualisation.plot_data_as_graph(training_data[0], title=training_labels[0])\n",
    "# except Exception as e:\n",
    "#     print(\"Error plotting data as image: \", e)\n",
    "#     pass\n",
    "\n",
    "# # training_data = np.expand_dims(training_data, axis=3)\n",
    "# # testing_data = np.expand_dims(testing_data, axis=3)\n",
    "\n",
    "# # Verify that the data and labels are the same shape\n",
    "# print(\"\")\n",
    "# print(\"Training data shape:\", training_data.shape)\n",
    "# print(\"Training data[0] shape:\", training_data[0].shape)\n",
    "# print(\"\")\n",
    "# print(\"Training labels shape:\", training_labels.shape)\n",
    "# print(\"Training labels[0]:\", training_labels[0])\n",
    "# # print(\"All training labels:\", training_labels)\n",
    "\n",
    "# if len(testing_data) > 0:\n",
    "#     print(\"Testing data shape:\", testing_data.shape)\n",
    "#     # print(\"Testing data[0] shape:\", testing_data[0].shape)\n",
    "#     print(\"\")\n",
    "#     print(\"Testing labels shape:\", testing_labels.shape)\n",
    "#     # print(\"Testing labels[0]:\", testing_labels[0])\n",
    "# else:\n",
    "#     print(\"No testing data\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specifying our model and training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256 #128\n",
    "epochs = 512\n",
    "curr_model = ModelName.BEERNET_LITE#_EXPERIMENTAL\n",
    "include_preprocessing_layers = True\n",
    "\n",
    "# Trying out various input shapes\n",
    "# input_shape = np.expand_dims(training_data[0], axis=2).shape\n",
    "# input_shape = (100, 3, 1)\n",
    "# input_shape = (50, 2, 3)\n",
    "# input_shape = (25, 4, 3)\n",
    "input_shape = (20, 5, 3)\n",
    "# input_shape = (10, 10, 3)\n",
    "print(\"Input shape:\", input_shape)\n",
    "\n",
    "# Number of classes is the number of gestures, which is the number of output neurons\n",
    "num_classes = len(data_loading.GestureNames)\n",
    "\n",
    "model: tf.keras.Model = ModelConstructor.get_model(model=curr_model, input_shape=input_shape, \n",
    "                                                   num_classes=num_classes, include_preprocessing=include_preprocessing_layers)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                  metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "# Before K-fold cross validation, store the initial weights of the model, \n",
    "# so that we can train the model from scratch on the entire dataset after K-fold cross validation without recompiling the model\n",
    "initial_weights = model.get_weights()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model using K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General training of the model\n",
    "# model.fit(training_data, training_labels, batch_size=32, epochs=250)\n",
    "# model.fit(training_data, training_labels, batch_size=64, epochs=500)\n",
    "\n",
    "# Perform k-fold cross validation\n",
    "k = min(6, len(all_candidates))\n",
    "\n",
    "kfold = sk.model_selection.StratifiedKFold(n_splits=k, shuffle=True, random_state=sklearn_random_seed)\n",
    "kfold_scores = []\n",
    "confusion_matrices = []\n",
    "histories = []\n",
    "\n",
    "all_candidates = np.array(all_candidates)\n",
    "\n",
    "# Since there is an imbalance in the dataset we make use of stratified k-fold cross validation\n",
    "# Make a list of labels that correspond to the candidate's used hand. \n",
    "# If the candidate used their left hand, the label is 0, otherwise it is 1\n",
    "# Currently, done by checking if the candidate's name contains \"_L\", probably not the best way\n",
    "hand_labels = [0 if \"_L\" in candidate else 1 for candidate in all_candidates]\n",
    "\n",
    "print(f\"Training model with architecture: {curr_model.name} with {k}-fold cross validation\")\n",
    "print(f\"Using {len(all_candidates)} candidates\")\n",
    "print(\"-----------------------------------\")\n",
    "\n",
    "for idx, (train, test) in enumerate(kfold.split(all_candidates, hand_labels)):\n",
    "    print(f\"Fold {idx + 1} of {k}. Training on: {train}, testing on {test}\")\n",
    "    print(\"Train candidates:\", all_candidates[train], \"Test candidates:\", all_candidates[test])\n",
    "    \n",
    "    # Specifying the model and compiling it\n",
    "    model = ModelConstructor.get_model(model=curr_model, input_shape=input_shape, \n",
    "                                       num_classes=num_classes, include_preprocessing=include_preprocessing_layers)\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                  metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "    \n",
    "    # model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    #                 loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    #                 metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "    \n",
    "    # Getting the training and testing data\n",
    "    train_features, train_labels = data_loading.get_data_and_labels_from_candidates(all_candidates[train], all_data_per_candidate, input_shape=input_shape)\n",
    "    test_features, test_labels = data_loading.get_data_and_labels_from_candidates(all_candidates[test], all_data_per_candidate, input_shape=input_shape)\n",
    "\n",
    "    # Converting the labels to integers, important for the loss function to work\n",
    "    train_labels = data_loading.map_labels_to_integers(train_labels)\n",
    "    test_labels = data_loading.map_labels_to_integers(test_labels)\n",
    "    # train_labels = data_loading.map_labels_to_one_hot_encoding(train_labels)\n",
    "    # test_labels = data_loading.map_labels_to_one_hot_encoding(test_labels)\n",
    "\n",
    "    # Training the model\n",
    "    history = model.fit(train_features, train_labels, batch_size=batch_size, epochs=epochs, verbose = 0)\n",
    "\n",
    "    # Gathering results of this fold\n",
    "    histories.append(history)\n",
    "    score = model.evaluate(test_features, test_labels, verbose=0)\n",
    "    print(\"Loss and accuracy:\", score)\n",
    "    kfold_scores.append(score)\n",
    "    confusion_matrices.append(sk.metrics.confusion_matrix(test_labels, np.argmax(model.predict(test_features), axis=1)))\n",
    "\n",
    "    print(\"-----------------------------------\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing some of the validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"K-fold scores:\", kfold_scores)\n",
    "print(\"Average k-fold score:\", np.mean(kfold_scores, axis=0))\n",
    "print(\"Std k-fold score:\", np.std(kfold_scores, axis=0))\n",
    "\n",
    "# Plot the confusion matrix\n",
    "confusion_matrix = np.mean(confusion_matrices, axis=0)\n",
    "data_visualisation.plot_confusion_matrix(confusion_matrix, [gesture.value for gesture in data_loading.GestureNames], normalize=True)\n",
    "\n",
    "# Plot the training history by averaging the histories over the k-folds\n",
    "loss = np.mean([history.history['loss'] for history in histories], axis=0)\n",
    "accuracy = np.mean([history.history['sparse_categorical_accuracy'] for history in histories], axis=0)\n",
    "# accuracy = np.mean([history.history['categorical_accuracy'] for history in histories], axis=0)\n",
    "data_visualisation.plot_loss_and_accuracy(loss, accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model with the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After K-fold cross validation, reset the weights of the model to the initial weights\n",
    "model.set_weights(initial_weights)\n",
    "\n",
    "all_data, all_labels = data_loading.get_data_and_labels_from_candidates(list(all_data_per_candidate.keys()), all_data_per_candidate, input_shape=input_shape)\n",
    "\n",
    "# Print all candidates, for checking purposes\n",
    "print(\"All candidates:\", all_candidates)\n",
    "\n",
    "# Print length of entire dataset\n",
    "print(\"Length of all data:\", all_data.shape)\n",
    "\n",
    "# And now we can train the model on all the data (training + testing)\n",
    "# model.fit(training_data, training_labels, batch_size=batch_size, epochs=epochs, verbose = 0)\n",
    "# model.fit(testing_data, testing_labels, batch_size=batch_size, epochs=epochs, verbose = 0)\n",
    "all_labels = data_loading.map_labels_to_integers(all_labels)\n",
    "model.fit(all_data, all_labels, batch_size=batch_size, epochs=epochs, verbose = 0)\n",
    "\n",
    "\n",
    "# history = model.history.history\n",
    "# print(\"History:\", history)\n",
    "\n",
    "# Plot the loss and accuracy\n",
    "# data_visualisation.plot_loss_and_accuracy(history['loss'], history['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false\n",
    "# i = 5\n",
    "# # Needed because the model expects a batch of data, not a single sample\n",
    "# reshaped_data = np.expand_dims(testing_data[i], axis=0)\n",
    "\n",
    "# print(\"Data shape: \", reshaped_data.shape)\n",
    "\n",
    "# print(\"Predictions: \", model.predict(reshaped_data))\n",
    "# print(\"Actual label: \", gesture_classes[training_labels[i]])\n",
    "# print(\"Predicted label: \", gesture_classes[np.argmax(model.predict(reshaped_data))])\n",
    "\n",
    "\n",
    "# This is not needed if we use K-fold cross validation\n",
    "\n",
    "predictions = model.predict(testing_data)\n",
    "\n",
    "gesture_classes = list(data_loading.GestureNames)\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    with np.printoptions(precision=6, suppress=True):\n",
    "        print(f\"Actual: {gesture_classes[testing_labels[i]]}, Predicted: {gesture_classes[np.argmax(predictions[i])]}\")\n",
    "        print(f\"Confidence of prediction: {np.max(predictions[i])}, All predictions: {predictions[i]}\")\n",
    "\n",
    "    # Plot sample if it is wrong\n",
    "    if testing_labels[i] != np.argmax(predictions[i]):\n",
    "        try:\n",
    "            data_visualisation.plot_data_as_image(testing_data[i], label=f\"Predicted: {gesture_classes[np.argmax(predictions[i])]}, Actual: {gesture_classes[testing_labels[i]]}\")\n",
    "            data_visualisation.plot_data_as_graph(testing_data[i], title=f\"Predicted: {gesture_classes[np.argmax(predictions[i])]}, Actual: {gesture_classes[testing_labels[i]]}\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    print(\"\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting our model for TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script skip cell --no-raise-error\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "def representative_data_generator():\n",
    "    for i in range(min(1000, len(all_data))):\n",
    "        sample_data = np.random.rand(*input_shape)\n",
    "        sample_data = np.expand_dims(sample_data, axis=0)\n",
    "        # sample_data = np.expand_dims(sample_data, axis=3)\n",
    "        yield [sample_data.astype(np.float32)]\n",
    "\n",
    "# for data in representative_data_generator():\n",
    "#     print(data)\n",
    "\n",
    "converter.representative_dataset = representative_data_generator\n",
    "# converter.target_spec.supported_ops = []\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "# converter._experimental_new_quantizer = True\n",
    "converter.allow_custom_ops = True\n",
    "# converter.target_spec.supported_types = [tf.int8]\n",
    "\n",
    "# converter.inference_input_type = tf.float32\n",
    "# converter.inference_output_type = tf.uint8\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "open(\"converted_model.tflite\", \"wb\").write(tflite_model)\n",
    "\n",
    "print(\"Model converted to tflite\")\n",
    "\n",
    "# interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "\n",
    "# print(\"input details:\", interpreter.get_input_details())\n",
    "# print(\"output details:\", interpreter.get_output_details())\n",
    "# print(\"input shape:\", interpreter.get_input_details()[0]['shape'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating compressed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test the tflite model\n",
    "\n",
    "# Load the TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=\"converted_model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "signature = interpreter.get_signature_runner()\n",
    "\n",
    "# Get one sample of data to test the model from all the data\n",
    "# Use the first sample of data\n",
    "i = 123\n",
    "sample_data = np.expand_dims(all_data[i], axis=0)\n",
    "# sample_data = all_data[i]\n",
    "print(\"Label: \", all_labels[i])\n",
    "output = signature(sensor_image=sample_data.astype(np.float32))\n",
    "print(\"Output:\", output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting the TFLite to C code\n",
    "\n",
    "Run this command:\n",
    "\n",
    "```\n",
    "xxd -i converted_model.tflite > model_data.cc\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
